{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc48c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. How does bagging reduce overfitting in decision trees?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e700fe",
   "metadata": {},
   "source": [
    "#### Bagging attempts to reduce the chance of overfitting complex models. It trains a large number of “strong” learners in parallel. A strong learner is a model that's relatively unconstrained. Bagging then combines all the strong learners together in order to “smooth out” their predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0f8592",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. What are the advantages and disadvantages of using different types of base learners in bagging?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef7359d",
   "metadata": {},
   "source": [
    "#### Bagging offers the advantage of allowing many weak learners to combine efforts to outdo a single strong learner. It also helps in the reduction of variance, hence eliminating the overfitting of models in the procedure. One disadvantage of bagging is that it introduces a loss of interpretability of a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c734e42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. How does the choice of base learner affect the bias-variance tradeoff in bagging?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33a9abd",
   "metadata": {},
   "source": [
    "#### Bagging is meant to reduce the variance without increasing the bias. This technique is especially effective where minute changes in a learner’s training set lead to huge changes in the predicted output. Bagging reduces the variance by aggregating individual models. These models have dissimilar statistical properties like the means and standard deviations, among others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a6a940",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. Can bagging be used for both classification and regression tasks? How does it differ in each case?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ec74e4",
   "metadata": {},
   "source": [
    "#### Yes Bagging can use for both classification and regression tasks.\n",
    "\n",
    "-- In classification, whcih ever output has majority voting that is the output.\n",
    " \n",
    "-- Regression, Averaging output of all the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29c0a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. What is the role of ensemble size in bagging? How many models should be included in the ensemble?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dffc6ed",
   "metadata": {},
   "source": [
    "#### We dont have any limit for number of models in ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb68d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. Can you provide an example of a real-world application of bagging in machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e82fd4",
   "metadata": {},
   "source": [
    "#### Any thing we use Machine learning algorithms, can be solved with bagging.\n",
    "\n",
    "-- house prediction with features of number of rooms, flat size and locality."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
