{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf076245",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is an ensemble technique in machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb1599e",
   "metadata": {},
   "source": [
    "#### An ensemble method is a technique which uses multiple independent similar or different models/weak learners to derive an output or make some predictions. For e.g. A random forest is an ensemble of multiple decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e412234",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. Why are ensemble techniques used in machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50c081c",
   "metadata": {},
   "source": [
    "#### There are two main reasons to use an ensemble over a single model, and they are related; they are: Performance: An ensemble can make better predictions and achieve better performance than any single contributing model. Robustness: An ensemble reduces the spread or dispersion of the predictions and model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a3c9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. What is bagging?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab71871",
   "metadata": {},
   "source": [
    "#### Bagging, also known as bootstrap aggregation, is the ensemble learning method that is commonly used to reduce variance within a noisy dataset. In bagging, a random sample of data in a training set is selected with replacement—meaning that the individual data points can be chosen more than once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6382388",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. What is boosting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0d7877",
   "metadata": {},
   "source": [
    "#### Boosting is an ensemble learning method that combines a set of weak learners into a strong learner to minimize training errors. In boosting, a random sample of data is selected, fitted with a model and then trained sequentially—that is, each model tries to compensate for the weaknesses of its predecessor. With each iteration, the weak rules from each individual classifier are combined to form one, strong prediction rule. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fecd5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. What are the benefits of using ensemble techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca16bf5",
   "metadata": {},
   "source": [
    "#### 1. Ensemble methods have higher predictive accuracy, compared to the individual models.\n",
    "\n",
    "#### 2. Ensemble methods are very useful when there is both linear and non-linear type of data in the dataset; different models can be combined to handle this type of data.\n",
    "\n",
    "#### 3. With ensemble methods bias/variance can be reduced and most of the time, the model is not under fitted/overfitted.\n",
    "\n",
    "#### 4. Ensemble of models is always less noisy and more stable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea36b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. Are ensemble techniques always better than individual models?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bee853",
   "metadata": {},
   "source": [
    "#### There are two main reasons to use an ensemble over a single model, and they are related; they are: \n",
    "\n",
    "-- Performance: An ensemble can make better predictions and achieve better performance than any single contributing model.\n",
    "\n",
    "-- Robustness: An ensemble reduces the spread or dispersion of the predictions and model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343f5bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7. How is the confidence interval calculated using bootstrap?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6030b3d6",
   "metadata": {},
   "source": [
    "## Confidance interval of 95% can calculate using below code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6c533cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "df=sns.load_dataset(\"tips\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2f550c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=df['tip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "421fc420",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d9bb262",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### create function for creating bootstrap samples\n",
    "\n",
    "def draw_bs_replicates(data,func,size):\n",
    "    \"\"\"creates a bootstrap sample, computes replicates and returns replicates array\"\"\"\n",
    "    # Create an empty array to store replicates\n",
    "    bs_replicates = np.empty(size)\n",
    "    \n",
    "    # pull bootstrapped samples\n",
    "    for i in range(size):\n",
    "        # Create a bootstrap sample\n",
    "        bs_sample = np.random.choice(data,size)\n",
    "        # Get bootstrap replicate and append to bs_replicates\n",
    "        bs_replicates[i] = func(bs_sample)\n",
    "    \n",
    "    return bs_replicates\n",
    "\n",
    "\n",
    "# draw bootstrap samples of the statistic or parameter estimate of interest\n",
    "bs_replicates = draw_bs_replicates(data,np.mean,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c14b6e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.670975, 3.26359 ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(bs_replicates,[2.5,97.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a5516c",
   "metadata": {},
   "source": [
    "#### Confidance interval range is [2.670975, 3.26359 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6ba802",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q8. How does bootstrap work and What are the steps involved in bootstrap?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61004a2e",
   "metadata": {},
   "source": [
    "-- The bootstrap method involves iteratively resampling a dataset with replacement.\n",
    "\n",
    "-- That when using the bootstrap you must choose the size of the sample and the number of repeats.\n",
    "\n",
    "-- The scikit-learn provides a function that you can use to resample a dataset for the bootstrap method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f4aeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q9. A researcher wants to estimate the mean height of a population of trees. They measure the height of a \n",
    "sample of 50 trees and obtain a mean height of 15 meters and a standard deviation of 2 meters. Use \n",
    "bootstrap to estimate the 95% confidence interval for the population mean height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "673e8506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14.445628283549746, 15.554371716450254)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "15-1.96*2/np.sqrt(50),15+1.96*2/np.sqrt(50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
